'''1. Найдите сайт, содержащий интересующий вас список или каталог.
Это может быть список книг, фильмов, спортивных команд или что-то еще, что вас заинтересовало.
2. Создайте новый проект Scrapy и определите нового паука.
С помощью атрибута start_urls укажите URL выбранной вами веб-страницы.
3. Определите метод парсинга для извлечения интересующих вас данных.
Используйте селекторы XPath или CSS для навигации по HTML и извлечения данных.
Возможно, потребуется извлечь данные с нескольких страниц или перейти по ссылкам на другие страницы.
4. Сохраните извлеченные данные в структурированном формате.
Вы можете использовать оператор yield для возврата данных из паука, которые Scrapy может записать в файл в выбранном вами формате (например, JSON или CSV).
5. Конечным результатом работы должен быть код Scrapy Spider, а также пример выходных данных.
Не забывайте соблюдать правила robots.txt и условия обслуживания веб-сайта, а также ответственно подходите к использованию веб-скрейпинга.
'''

'''В данном задании в качестве целевого сайта выбрана статья википедии "Index of Economic Freedom".
С помощью кода извлекаем данные таблицы, содержащей названия стран, ранжированных по индексу экономической свободы.
'''


import scrapy


class CountrySpiderSpider(scrapy.Spider):
    name = "country_spider"
    allowed_domains = ["en.wikipedia.org"]
    start_urls = ["https://en.wikipedia.org/wiki/Index_of_Economic_Freedom"]

    def parse(self, response):
        countries = response.xpath("//tbody/tr")
        for country in countries:
            name = country.xpath(".//td[1]/a/text()").get()
            rank = country.xpath(".//td[2]/text()").get()
            score = country.xpath(".//td[3]/text()").get()
            yield {
                'country_name': name,
                'Rank': rank,
                'Score': score,
            }
